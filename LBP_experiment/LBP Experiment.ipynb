{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stirunag/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "# file = '/home/stirunag/pre-trained_word_embeddings/glove/glove.6B.50d.txt'\n",
    "# glove2word2vec(glove_input_file=file, word2vec_output_file=\"gensim_glove.6B.50d.txt\")\n",
    "\n",
    "###Finally, read the word2vec txt to a gensim model using KeyedVectors:\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# glove_model = KeyedVectors.load_word2vec_format(\"gensim_glove.6B.50d.txt\", binary=False)\n",
    "\n",
    "\n",
    "glove_model = KeyedVectors.load_word2vec_format(\"/home/stirunag/pre-trained_word_embeddings/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9596675038337708\n",
      "0.1212424486875534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stirunag/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import spatial\n",
    "\n",
    "index2word_set = set(glove_model.wv.index2word)\n",
    "\n",
    "\n",
    "def avg_feature_vector(sentence, model, num_features, index2word_set):\n",
    "    words = sentence.split()\n",
    "    feature_vec = np.zeros((num_features, ), dtype='float32')\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            n_words += 1\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "    if (n_words > 0):\n",
    "        feature_vec = np.divide(feature_vec, n_words)\n",
    "    return feature_vec\n",
    "\n",
    "\n",
    "s1_afv = avg_feature_vector('this is a sentence', model=glove_model,   num_features=300, index2word_set=index2word_set)\n",
    "s2_afv = avg_feature_vector('this is also sentence', model=glove_model,num_features=300, index2word_set=index2word_set)\n",
    "sim = 1 - spatial.distance.cosine(s1_afv, s2_afv)\n",
    "print(sim)\n",
    "\n",
    "\n",
    "s1_afv = avg_feature_vector('apple cider banana', model=glove_model,   num_features=300, index2word_set=index2word_set)\n",
    "s2_afv = avg_feature_vector('this is also sentence', model=glove_model,num_features=300, index2word_set=index2word_set)\n",
    "sim = 1 - spatial.distance.cosine(s1_afv, s2_afv)\n",
    "print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def kullback_leibler_divergence(p, q):\n",
    "    p = np.asarray(p)\n",
    "    q = np.asarray(q)\n",
    "    filt = np.logical_and(p != 0, q != 0)\n",
    "    return np.sum(p[filt] * np.log2(p[filt] / q[filt]))\n",
    "\n",
    "def concatenate_feature_vector(sentence, model, num_features, index2word_set):\n",
    "    words = sentence.split()\n",
    "    feature_vec =  np.array([])  #np.zeros((num_features, len(words)), dtype='float32')\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            n_words += 1\n",
    "            feature_vec = np.append(feature_vec, np.transpose(glove_model[word]))#np.add(feature_vec, model[word])\n",
    "    \n",
    "    return feature_vec.reshape((n_words, num_features))\n",
    "\n",
    "\n",
    "def extract_1dlbp_cpu(input, neighborhood, p):\n",
    "    \"\"\"\n",
    "    Extract the 1d lbp pattern\n",
    "    \"\"\"\n",
    "    res = np.zeros(1 << (2 * neighborhood))\n",
    "    for i in range(neighborhood, len(input) - neighborhood):\n",
    "        left = input[i - neighborhood : i]\n",
    "        right = input[i + 1 : i + neighborhood + 1]\n",
    "        both = np.r_[left, right]\n",
    "        res[np.sum(p [both >= input[i]])] += 1\n",
    "    return res\n",
    "\n",
    "\n",
    "def LBP_1D_avg_feature_vector(sentence, model, num_features, index2word_set, neighborhood, powers):\n",
    "    words = sentence.split()\n",
    "    feature_vec = np.zeros((1 << (2 * neighborhood), ), dtype='float32')\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            n_words += 1\n",
    "            LBP_hist = extract_1dlbp_cpu(model[word], neighborhood, powers)\n",
    "            feature_vec = np.add(feature_vec, LBP_hist)\n",
    "    if (n_words > 0):\n",
    "        feature_vec = np.divide(feature_vec, n_words)\n",
    "    return feature_vec\n",
    "\n",
    "\n",
    "class LocalBinaryPatterns:\n",
    "    def __init__(self, numPoints, radius):\n",
    "    # store the number of points and radius\n",
    "        self.numPoints = numPoints\n",
    "        self.radius = radius\n",
    " \n",
    "    def describe(self, image, eps=1e-7):\n",
    "        # compute the Local Binary Pattern representation\n",
    "        # of the image, and then use the LBP representation\n",
    "        # to build the histogram of patterns\n",
    "        lbp = feature.local_binary_pattern(image, self.numPoints,\n",
    "            self.radius, method=\"var\")\n",
    "        (hist, _) = np.histogram(lbp.ravel(),\n",
    "            bins=np.arange(0, self.numPoints + 3),\n",
    "            range=(0, self.numPoints + 2))\n",
    "\n",
    "        # normalize the histogram\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + eps)\n",
    "\n",
    "        # return the histogram of Local Binary Patterns\n",
    "        return hist\n",
    "    \n",
    "    \n",
    "def chiSquared(p,q):\n",
    "    return 0.5*np.sum((p-q)**2/(p+q+1e-6))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_cfv = concatenate_feature_vector('apple banana mango doctor', glove_model,300, index2word_set)\n",
    "s2_cfv = concatenate_feature_vector('this is sentence structure', glove_model,300, index2word_set)\n",
    "\n",
    "desc = LocalBinaryPatterns(24, 8)                       \n",
    "\n",
    "hist1 = desc.describe(Image.fromarray(s1_cfv))\n",
    "hist2 = desc.describe(Image.fromarray(s2_cfv))\n",
    "\n",
    "sim = 1 - chiSquared(hist1, hist2)\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kullback_leibler_divergence(hist1, hist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import the necessary packages\n",
    "# from scipy.spatial import distance as dist\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import argparse\n",
    "# import glob\n",
    "# # import cv2\n",
    "\n",
    "# # https://www.pyimagesearch.com/2014/07/14/3-ways-compare-histograms-using-opencv-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 1D LBP experiment\n",
    "\n",
    "neighborhood = 13\n",
    "powers_ = 1 << np.array(range(0, 2 * neighborhood), dtype='int32')\n",
    "\n",
    "s1_1D_cfv = LBP_1D_avg_feature_vector('this is sentence structure', glove_model,300, index2word_set,neighborhood,powers_)\n",
    "s2_1D_cfv = LBP_1D_avg_feature_vector('this is sentence structure',glove_model,300, index2word_set,neighborhood,powers_)\n",
    "\n",
    "sim = 1 - chiSquared(s1_1D_cfv, s2_1D_cfv)\n",
    "print(sim)\n",
    "\n",
    "print(kullback_leibler_divergence(s1_1D_cfv, s2_1D_cfv))\n",
    "\n",
    "print(1 - spatial.distance.cosine(s1_1D_cfv, s2_1D_cfv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,) (64,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-e188190bcab4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex2word_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mLBP_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_1dlbp_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighborhood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mfeature_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLBP_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,) (64,) "
     ]
    }
   ],
   "source": [
    "sentence = 'apple banana mango doctor'\n",
    "words = sentence.split()\n",
    "feature_vec = np.zeros((2^8, ), dtype='float32')\n",
    "\n",
    "for word in words:\n",
    "    if word in index2word_set:\n",
    "        LBP_hist = extract_1dlbp_cpu(glove_model[word], neighborhood, p)\n",
    "        feature_vec = np.add(feature_vec, LBP_hist)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-ac5d2926cb67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mneighborhood\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "    words = sentence.split()\n",
    "    feature_vec = np.zeros((num_features, ), dtype='float32')\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            n_words += 1\n",
    "            LBP_hist = extract_1dlbp_cpu(model[word], neighborhood, powers)\n",
    "            feature_vec = np.add(feature_vec, LBP_hist)\n",
    "    if (n_words > 0):\n",
    "        feature_vec = np.divide(feature_vec, n_words)\n",
    "    return feature_vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
